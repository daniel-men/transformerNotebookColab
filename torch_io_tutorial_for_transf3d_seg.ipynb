{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_io tutorial for transf3d seg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniel-men/transformerNotebookColab/blob/main/torch_io_tutorial_for_transf3d_seg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFGq4NTRNfyJ"
      },
      "source": [
        "## self-attention-cv : illustration of a training process with subvolume sampling for 3d segmentation\n",
        "\n",
        "The dataset can be found here: https://iseg2019.web.unc.edu/ . i uploaded it and mounted from my gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clse_QTnggr-",
        "outputId": "7a06dbad-a3fa-451a-d22e-1989cf420a2e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "import tarfile\n",
        "root_path = '/gdrive/My Drive/Task01_BrainTumour.tar' \n",
        "!echo \"Download and extracting folders...\"\n",
        "zip_ref = tarfile.TarFile(root_path, 'r')\n",
        "zip_ref.extractall(\"./\")\n",
        "zip_ref.close()\n",
        "!echo \"Finished\"\n",
        "!pip install torchio\n",
        "!pip install self-attention-cv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "Download and extracting folders...\n",
            "Finished\n",
            "Collecting torchio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/33/94812ae74a2815fdd5bf7c4e26be75086ebc770309c569380e6f7cc4ad60/torchio-0.18.29-py2.py3-none-any.whl (140kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 19.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.7/dist-packages (from torchio) (7.1.2)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (from torchio) (0.5.1)\n",
            "Collecting Deprecated\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/56/7d4774533d2c119e1873993d34d313c9c9efc88c5e4ab7e33bdf915ad98c/Deprecated-1.2.11-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchio) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchio) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.8.0+cu101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torchio) (1.4.1)\n",
            "Collecting SimpleITK<2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/ee/638b6bae2db10e5ef4ca94c95bb29ec25aa37a9d721b47f91077d7e985e0/SimpleITK-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 63kB/s \n",
            "\u001b[?25hRequirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from torchio) (3.0.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->torchio) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->torchio) (3.7.4.3)\n",
            "Installing collected packages: Deprecated, SimpleITK, torchio\n",
            "Successfully installed Deprecated-1.2.11 SimpleITK-1.2.4 torchio-0.18.29\n",
            "Collecting self-attention-cv\n",
            "  Downloading https://files.pythonhosted.org/packages/69/5b/4163230c657f80a5f4123af111a410257df5d0c3d26027bd150c40b75fec/self_attention_cv-1.1.0-py3-none-any.whl\n",
            "Collecting pytest>=6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/cf/7f67585bd2fc0359ec482cf3c430bce3ef6d3f40bc468137225a733e3069/pytest-6.2.2-py3-none-any.whl (280kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 18.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.8 in /usr/local/lib/python3.7/dist-packages (from self-attention-cv) (0.9.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from self-attention-cv) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from self-attention-cv) (1.8.0+cu101)\n",
            "Collecting einops>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2->self-attention-cv) (20.9)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2->self-attention-cv) (1.10.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2->self-attention-cv) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2->self-attention-cv) (3.7.0)\n",
            "Collecting pluggy<1.0.0a1,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2->self-attention-cv) (20.3.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2->self-attention-cv) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8->self-attention-cv) (7.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->self-attention-cv) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest>=6.2->self-attention-cv) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=6.2->self-attention-cv) (3.4.1)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pluggy, pytest, einops, self-attention-cv\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed einops-0.3.0 pluggy-0.13.1 pytest-6.2.2 self-attention-cv-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkI_JENCCzPj",
        "outputId": "2cf8f641-3ef2-4f7e-b610-8ac7b5a76175"
      },
      "source": [
        "!ls ./Task01_BrainTumour\r\n",
        "!ls ./Task01_BrainTumour/imagesTr\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset.json  imagesTr\timagesTs  labelsTr\n",
            "BRATS_001.nii.gz  BRATS_122.nii.gz  BRATS_243.nii.gz  BRATS_364.nii.gz\n",
            "BRATS_002.nii.gz  BRATS_123.nii.gz  BRATS_244.nii.gz  BRATS_365.nii.gz\n",
            "BRATS_003.nii.gz  BRATS_124.nii.gz  BRATS_245.nii.gz  BRATS_366.nii.gz\n",
            "BRATS_004.nii.gz  BRATS_125.nii.gz  BRATS_246.nii.gz  BRATS_367.nii.gz\n",
            "BRATS_005.nii.gz  BRATS_126.nii.gz  BRATS_247.nii.gz  BRATS_368.nii.gz\n",
            "BRATS_006.nii.gz  BRATS_127.nii.gz  BRATS_248.nii.gz  BRATS_369.nii.gz\n",
            "BRATS_007.nii.gz  BRATS_128.nii.gz  BRATS_249.nii.gz  BRATS_370.nii.gz\n",
            "BRATS_008.nii.gz  BRATS_129.nii.gz  BRATS_250.nii.gz  BRATS_371.nii.gz\n",
            "BRATS_009.nii.gz  BRATS_130.nii.gz  BRATS_251.nii.gz  BRATS_372.nii.gz\n",
            "BRATS_010.nii.gz  BRATS_131.nii.gz  BRATS_252.nii.gz  BRATS_373.nii.gz\n",
            "BRATS_011.nii.gz  BRATS_132.nii.gz  BRATS_253.nii.gz  BRATS_374.nii.gz\n",
            "BRATS_012.nii.gz  BRATS_133.nii.gz  BRATS_254.nii.gz  BRATS_375.nii.gz\n",
            "BRATS_013.nii.gz  BRATS_134.nii.gz  BRATS_255.nii.gz  BRATS_376.nii.gz\n",
            "BRATS_014.nii.gz  BRATS_135.nii.gz  BRATS_256.nii.gz  BRATS_377.nii.gz\n",
            "BRATS_015.nii.gz  BRATS_136.nii.gz  BRATS_257.nii.gz  BRATS_378.nii.gz\n",
            "BRATS_016.nii.gz  BRATS_137.nii.gz  BRATS_258.nii.gz  BRATS_379.nii.gz\n",
            "BRATS_017.nii.gz  BRATS_138.nii.gz  BRATS_259.nii.gz  BRATS_380.nii.gz\n",
            "BRATS_018.nii.gz  BRATS_139.nii.gz  BRATS_260.nii.gz  BRATS_381.nii.gz\n",
            "BRATS_019.nii.gz  BRATS_140.nii.gz  BRATS_261.nii.gz  BRATS_382.nii.gz\n",
            "BRATS_020.nii.gz  BRATS_141.nii.gz  BRATS_262.nii.gz  BRATS_383.nii.gz\n",
            "BRATS_021.nii.gz  BRATS_142.nii.gz  BRATS_263.nii.gz  BRATS_384.nii.gz\n",
            "BRATS_022.nii.gz  BRATS_143.nii.gz  BRATS_264.nii.gz  BRATS_385.nii.gz\n",
            "BRATS_023.nii.gz  BRATS_144.nii.gz  BRATS_265.nii.gz  BRATS_386.nii.gz\n",
            "BRATS_024.nii.gz  BRATS_145.nii.gz  BRATS_266.nii.gz  BRATS_387.nii.gz\n",
            "BRATS_025.nii.gz  BRATS_146.nii.gz  BRATS_267.nii.gz  BRATS_388.nii.gz\n",
            "BRATS_026.nii.gz  BRATS_147.nii.gz  BRATS_268.nii.gz  BRATS_389.nii.gz\n",
            "BRATS_027.nii.gz  BRATS_148.nii.gz  BRATS_269.nii.gz  BRATS_390.nii.gz\n",
            "BRATS_028.nii.gz  BRATS_149.nii.gz  BRATS_270.nii.gz  BRATS_391.nii.gz\n",
            "BRATS_029.nii.gz  BRATS_150.nii.gz  BRATS_271.nii.gz  BRATS_392.nii.gz\n",
            "BRATS_030.nii.gz  BRATS_151.nii.gz  BRATS_272.nii.gz  BRATS_393.nii.gz\n",
            "BRATS_031.nii.gz  BRATS_152.nii.gz  BRATS_273.nii.gz  BRATS_394.nii.gz\n",
            "BRATS_032.nii.gz  BRATS_153.nii.gz  BRATS_274.nii.gz  BRATS_395.nii.gz\n",
            "BRATS_033.nii.gz  BRATS_154.nii.gz  BRATS_275.nii.gz  BRATS_396.nii.gz\n",
            "BRATS_034.nii.gz  BRATS_155.nii.gz  BRATS_276.nii.gz  BRATS_397.nii.gz\n",
            "BRATS_035.nii.gz  BRATS_156.nii.gz  BRATS_277.nii.gz  BRATS_398.nii.gz\n",
            "BRATS_036.nii.gz  BRATS_157.nii.gz  BRATS_278.nii.gz  BRATS_399.nii.gz\n",
            "BRATS_037.nii.gz  BRATS_158.nii.gz  BRATS_279.nii.gz  BRATS_400.nii.gz\n",
            "BRATS_038.nii.gz  BRATS_159.nii.gz  BRATS_280.nii.gz  BRATS_401.nii.gz\n",
            "BRATS_039.nii.gz  BRATS_160.nii.gz  BRATS_281.nii.gz  BRATS_402.nii.gz\n",
            "BRATS_040.nii.gz  BRATS_161.nii.gz  BRATS_282.nii.gz  BRATS_403.nii.gz\n",
            "BRATS_041.nii.gz  BRATS_162.nii.gz  BRATS_283.nii.gz  BRATS_404.nii.gz\n",
            "BRATS_042.nii.gz  BRATS_163.nii.gz  BRATS_284.nii.gz  BRATS_405.nii.gz\n",
            "BRATS_043.nii.gz  BRATS_164.nii.gz  BRATS_285.nii.gz  BRATS_406.nii.gz\n",
            "BRATS_044.nii.gz  BRATS_165.nii.gz  BRATS_286.nii.gz  BRATS_407.nii.gz\n",
            "BRATS_045.nii.gz  BRATS_166.nii.gz  BRATS_287.nii.gz  BRATS_408.nii.gz\n",
            "BRATS_046.nii.gz  BRATS_167.nii.gz  BRATS_288.nii.gz  BRATS_409.nii.gz\n",
            "BRATS_047.nii.gz  BRATS_168.nii.gz  BRATS_289.nii.gz  BRATS_410.nii.gz\n",
            "BRATS_048.nii.gz  BRATS_169.nii.gz  BRATS_290.nii.gz  BRATS_411.nii.gz\n",
            "BRATS_049.nii.gz  BRATS_170.nii.gz  BRATS_291.nii.gz  BRATS_412.nii.gz\n",
            "BRATS_050.nii.gz  BRATS_171.nii.gz  BRATS_292.nii.gz  BRATS_413.nii.gz\n",
            "BRATS_051.nii.gz  BRATS_172.nii.gz  BRATS_293.nii.gz  BRATS_414.nii.gz\n",
            "BRATS_052.nii.gz  BRATS_173.nii.gz  BRATS_294.nii.gz  BRATS_415.nii.gz\n",
            "BRATS_053.nii.gz  BRATS_174.nii.gz  BRATS_295.nii.gz  BRATS_416.nii.gz\n",
            "BRATS_054.nii.gz  BRATS_175.nii.gz  BRATS_296.nii.gz  BRATS_417.nii.gz\n",
            "BRATS_055.nii.gz  BRATS_176.nii.gz  BRATS_297.nii.gz  BRATS_418.nii.gz\n",
            "BRATS_056.nii.gz  BRATS_177.nii.gz  BRATS_298.nii.gz  BRATS_419.nii.gz\n",
            "BRATS_057.nii.gz  BRATS_178.nii.gz  BRATS_299.nii.gz  BRATS_420.nii.gz\n",
            "BRATS_058.nii.gz  BRATS_179.nii.gz  BRATS_300.nii.gz  BRATS_421.nii.gz\n",
            "BRATS_059.nii.gz  BRATS_180.nii.gz  BRATS_301.nii.gz  BRATS_422.nii.gz\n",
            "BRATS_060.nii.gz  BRATS_181.nii.gz  BRATS_302.nii.gz  BRATS_423.nii.gz\n",
            "BRATS_061.nii.gz  BRATS_182.nii.gz  BRATS_303.nii.gz  BRATS_424.nii.gz\n",
            "BRATS_062.nii.gz  BRATS_183.nii.gz  BRATS_304.nii.gz  BRATS_425.nii.gz\n",
            "BRATS_063.nii.gz  BRATS_184.nii.gz  BRATS_305.nii.gz  BRATS_426.nii.gz\n",
            "BRATS_064.nii.gz  BRATS_185.nii.gz  BRATS_306.nii.gz  BRATS_427.nii.gz\n",
            "BRATS_065.nii.gz  BRATS_186.nii.gz  BRATS_307.nii.gz  BRATS_428.nii.gz\n",
            "BRATS_066.nii.gz  BRATS_187.nii.gz  BRATS_308.nii.gz  BRATS_429.nii.gz\n",
            "BRATS_067.nii.gz  BRATS_188.nii.gz  BRATS_309.nii.gz  BRATS_430.nii.gz\n",
            "BRATS_068.nii.gz  BRATS_189.nii.gz  BRATS_310.nii.gz  BRATS_431.nii.gz\n",
            "BRATS_069.nii.gz  BRATS_190.nii.gz  BRATS_311.nii.gz  BRATS_432.nii.gz\n",
            "BRATS_070.nii.gz  BRATS_191.nii.gz  BRATS_312.nii.gz  BRATS_433.nii.gz\n",
            "BRATS_071.nii.gz  BRATS_192.nii.gz  BRATS_313.nii.gz  BRATS_434.nii.gz\n",
            "BRATS_072.nii.gz  BRATS_193.nii.gz  BRATS_314.nii.gz  BRATS_435.nii.gz\n",
            "BRATS_073.nii.gz  BRATS_194.nii.gz  BRATS_315.nii.gz  BRATS_436.nii.gz\n",
            "BRATS_074.nii.gz  BRATS_195.nii.gz  BRATS_316.nii.gz  BRATS_437.nii.gz\n",
            "BRATS_075.nii.gz  BRATS_196.nii.gz  BRATS_317.nii.gz  BRATS_438.nii.gz\n",
            "BRATS_076.nii.gz  BRATS_197.nii.gz  BRATS_318.nii.gz  BRATS_439.nii.gz\n",
            "BRATS_077.nii.gz  BRATS_198.nii.gz  BRATS_319.nii.gz  BRATS_440.nii.gz\n",
            "BRATS_078.nii.gz  BRATS_199.nii.gz  BRATS_320.nii.gz  BRATS_441.nii.gz\n",
            "BRATS_079.nii.gz  BRATS_200.nii.gz  BRATS_321.nii.gz  BRATS_442.nii.gz\n",
            "BRATS_080.nii.gz  BRATS_201.nii.gz  BRATS_322.nii.gz  BRATS_443.nii.gz\n",
            "BRATS_081.nii.gz  BRATS_202.nii.gz  BRATS_323.nii.gz  BRATS_444.nii.gz\n",
            "BRATS_082.nii.gz  BRATS_203.nii.gz  BRATS_324.nii.gz  BRATS_445.nii.gz\n",
            "BRATS_083.nii.gz  BRATS_204.nii.gz  BRATS_325.nii.gz  BRATS_446.nii.gz\n",
            "BRATS_084.nii.gz  BRATS_205.nii.gz  BRATS_326.nii.gz  BRATS_447.nii.gz\n",
            "BRATS_085.nii.gz  BRATS_206.nii.gz  BRATS_327.nii.gz  BRATS_448.nii.gz\n",
            "BRATS_086.nii.gz  BRATS_207.nii.gz  BRATS_328.nii.gz  BRATS_449.nii.gz\n",
            "BRATS_087.nii.gz  BRATS_208.nii.gz  BRATS_329.nii.gz  BRATS_450.nii.gz\n",
            "BRATS_088.nii.gz  BRATS_209.nii.gz  BRATS_330.nii.gz  BRATS_451.nii.gz\n",
            "BRATS_089.nii.gz  BRATS_210.nii.gz  BRATS_331.nii.gz  BRATS_452.nii.gz\n",
            "BRATS_090.nii.gz  BRATS_211.nii.gz  BRATS_332.nii.gz  BRATS_453.nii.gz\n",
            "BRATS_091.nii.gz  BRATS_212.nii.gz  BRATS_333.nii.gz  BRATS_454.nii.gz\n",
            "BRATS_092.nii.gz  BRATS_213.nii.gz  BRATS_334.nii.gz  BRATS_455.nii.gz\n",
            "BRATS_093.nii.gz  BRATS_214.nii.gz  BRATS_335.nii.gz  BRATS_456.nii.gz\n",
            "BRATS_094.nii.gz  BRATS_215.nii.gz  BRATS_336.nii.gz  BRATS_457.nii.gz\n",
            "BRATS_095.nii.gz  BRATS_216.nii.gz  BRATS_337.nii.gz  BRATS_458.nii.gz\n",
            "BRATS_096.nii.gz  BRATS_217.nii.gz  BRATS_338.nii.gz  BRATS_459.nii.gz\n",
            "BRATS_097.nii.gz  BRATS_218.nii.gz  BRATS_339.nii.gz  BRATS_460.nii.gz\n",
            "BRATS_098.nii.gz  BRATS_219.nii.gz  BRATS_340.nii.gz  BRATS_461.nii.gz\n",
            "BRATS_099.nii.gz  BRATS_220.nii.gz  BRATS_341.nii.gz  BRATS_462.nii.gz\n",
            "BRATS_100.nii.gz  BRATS_221.nii.gz  BRATS_342.nii.gz  BRATS_463.nii.gz\n",
            "BRATS_101.nii.gz  BRATS_222.nii.gz  BRATS_343.nii.gz  BRATS_464.nii.gz\n",
            "BRATS_102.nii.gz  BRATS_223.nii.gz  BRATS_344.nii.gz  BRATS_465.nii.gz\n",
            "BRATS_103.nii.gz  BRATS_224.nii.gz  BRATS_345.nii.gz  BRATS_466.nii.gz\n",
            "BRATS_104.nii.gz  BRATS_225.nii.gz  BRATS_346.nii.gz  BRATS_467.nii.gz\n",
            "BRATS_105.nii.gz  BRATS_226.nii.gz  BRATS_347.nii.gz  BRATS_468.nii.gz\n",
            "BRATS_106.nii.gz  BRATS_227.nii.gz  BRATS_348.nii.gz  BRATS_469.nii.gz\n",
            "BRATS_107.nii.gz  BRATS_228.nii.gz  BRATS_349.nii.gz  BRATS_470.nii.gz\n",
            "BRATS_108.nii.gz  BRATS_229.nii.gz  BRATS_350.nii.gz  BRATS_471.nii.gz\n",
            "BRATS_109.nii.gz  BRATS_230.nii.gz  BRATS_351.nii.gz  BRATS_472.nii.gz\n",
            "BRATS_110.nii.gz  BRATS_231.nii.gz  BRATS_352.nii.gz  BRATS_473.nii.gz\n",
            "BRATS_111.nii.gz  BRATS_232.nii.gz  BRATS_353.nii.gz  BRATS_474.nii.gz\n",
            "BRATS_112.nii.gz  BRATS_233.nii.gz  BRATS_354.nii.gz  BRATS_475.nii.gz\n",
            "BRATS_113.nii.gz  BRATS_234.nii.gz  BRATS_355.nii.gz  BRATS_476.nii.gz\n",
            "BRATS_114.nii.gz  BRATS_235.nii.gz  BRATS_356.nii.gz  BRATS_477.nii.gz\n",
            "BRATS_115.nii.gz  BRATS_236.nii.gz  BRATS_357.nii.gz  BRATS_478.nii.gz\n",
            "BRATS_116.nii.gz  BRATS_237.nii.gz  BRATS_358.nii.gz  BRATS_479.nii.gz\n",
            "BRATS_117.nii.gz  BRATS_238.nii.gz  BRATS_359.nii.gz  BRATS_480.nii.gz\n",
            "BRATS_118.nii.gz  BRATS_239.nii.gz  BRATS_360.nii.gz  BRATS_481.nii.gz\n",
            "BRATS_119.nii.gz  BRATS_240.nii.gz  BRATS_361.nii.gz  BRATS_482.nii.gz\n",
            "BRATS_120.nii.gz  BRATS_241.nii.gz  BRATS_362.nii.gz  BRATS_483.nii.gz\n",
            "BRATS_121.nii.gz  BRATS_242.nii.gz  BRATS_363.nii.gz  BRATS_484.nii.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziryVMj3Z0Za"
      },
      "source": [
        "## Training example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_AgBbfvh6DV"
      },
      "source": [
        "import glob\n",
        "import torchio as tio\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "paths_t1 = sorted(glob.glob('./Task01_BrainTumour/imagesTr/*.nii.gz'))[:50]\n",
        "#paths_t2 = sorted(glob.glob('./iSeg-2019-Training/*T2.img'))\n",
        "paths_seg = sorted(glob.glob('./Task01_BrainTumour/labelsTr/*.nii.gz'))[:50]\n",
        "assert len(paths_t1) == len(paths_seg)\n",
        "\n",
        "subject_list = []\n",
        "for pat in zip(paths_t1, paths_seg):\n",
        "  path_t1, path_seg = pat\n",
        "  image = tio.ScalarImage(path_t1,)\n",
        "  t1 = tio.ScalarImage(tensor=image.data[:, :, :, 0].unsqueeze(0))\n",
        "  t2 = tio.ScalarImage(tensor=image.data[:, :, :, 2].unsqueeze(0))\n",
        "  subject = tio.Subject(t1=t1, t2=t2, label=tio.LabelMap(path_seg)) \n",
        "  subject_list.append(subject)\n",
        "\n",
        "\n",
        "transforms = [tio.RescaleIntensity((0, 1)),tio.RandomAffine() ]\n",
        "transform = tio.Compose(transforms)\n",
        "\n",
        "subjects_dataset = tio.SubjectsDataset(subject_list, transform=transform)\n",
        "\n",
        "patch_size = 24\n",
        "queue_length = 300\n",
        "samples_per_volume = 50\n",
        "sampler = tio.data.UniformSampler(patch_size)\n",
        "\n",
        "patches_queue = tio.Queue(\n",
        "subjects_dataset,\n",
        "queue_length,\n",
        "samples_per_volume,sampler, num_workers=1)\n",
        "\n",
        "patches_loader = DataLoader(patches_queue, batch_size=16)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vTzIMmWPSj9",
        "outputId": "318da5f8-4d8a-4060-8b22-60a79ba108a5"
      },
      "source": [
        "from self_attention_cv.Transformer3Dsegmentation import Transformer3dSeg\n",
        "\n",
        "def crop_target(img, target_size):\n",
        "  dim = img.shape[-1]\n",
        "  center = dim//2\n",
        "  start_dim = center - (target_size//2) - 1\n",
        "  end_dim = center + (target_size//2)\n",
        "  return img[:,0,start_dim:end_dim,start_dim:end_dim,start_dim:end_dim].long()\n",
        "\n",
        "target_size = 3 # as in the paper \n",
        "patch_dim = 8\n",
        "num_epochs = 50\n",
        "num_classes = 4\n",
        "model = Transformer3dSeg(subvol_dim=patch_size, patch_dim=patch_dim,\n",
        "                         in_channels=2, blocks=2, num_classes=num_classes).cuda()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "print(len(patches_loader))\n",
        "for epoch_index in range(num_epochs):\n",
        "  epoch_loss = 0\n",
        "  for c,patches_batch in enumerate(patches_loader):\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    input_t1 = patches_batch['t1'][tio.DATA]  \n",
        "    input_t2 = patches_batch['t2'][tio.DATA]\n",
        "\n",
        "    input_tensor = torch.cat([input_t1, input_t2], dim=1).cuda()\n",
        "    \n",
        "    \n",
        "    logits = model(input_tensor) # 8x8x8 the 3d transformer-based approach\n",
        "\n",
        "    # for the 3d transformer-based approach the target must be cropped again to the desired size\n",
        "    targets = patches_batch['label'][tio.DATA]  \n",
        "    \n",
        "    cropped_target = crop_target(targets, target_size).cuda()\n",
        "\n",
        "    loss = criterion(logits, cropped_target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss = epoch_loss+loss.cpu().item()\n",
        "\n",
        "  print(f'epoch {epoch_index} loss {epoch_loss/c}')\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157\n",
            "epoch 0 loss 0.19215610983948678\n",
            "epoch 1 loss 0.08945363417912561\n",
            "epoch 2 loss 0.09652531164913224\n",
            "epoch 3 loss 0.09292837228172292\n",
            "epoch 4 loss 0.09473018650299846\n",
            "epoch 5 loss 0.0801666445003297\n",
            "epoch 6 loss 0.09511692491240609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daV3W6hDK1Kz"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u02rAgE2K27R",
        "outputId": "da9b6239-51a5-4159-9057-7a33424fa3f3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchio as tio\n",
        "patch_overlap = 0\n",
        "patch_size = 24, 24, 24\n",
        "target_patch_size = 3\n",
        "\n",
        "#input sampling\n",
        "grid_sampler = tio.inference.GridSampler(subject_list[0], patch_size, patch_overlap)\n",
        "patch_loader = torch.utils.data.DataLoader(grid_sampler, batch_size=4)\n",
        "# target vol sampling\n",
        "grid_sampler_target = tio.inference.GridSampler(subject_list[0], target_patch_size, patch_overlap)\n",
        "aggregator = tio.inference.GridAggregator(grid_sampler_target)\n",
        "target_loader = torch.utils.data.DataLoader(grid_sampler_target, batch_size=4)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for patches_batch,target_patches in zip(patch_loader,target_loader):\n",
        "\n",
        "    input_t1 = patches_batch['t1'][tio.DATA]  \n",
        "    input_t2 = patches_batch['t2'][tio.DATA]\n",
        "    input_tensor = torch.cat([input_t1, input_t2], dim=1).float().cuda()\n",
        "\n",
        "    locations = target_patches[tio.LOCATION]\n",
        "    logits = model(input_tensor)\n",
        "    labels = logits.argmax(dim=tio.CHANNELS_DIMENSION, keepdim=True)\n",
        "    outputs = labels\n",
        "    aggregator.add_batch(outputs.type(torch.int32), locations)\n",
        "\n",
        "  print('output tensor shape:',outputs.shape)\n",
        "  output_tensor = aggregator.get_output_tensor()\n",
        "  print(output_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output tensor shape: torch.Size([4, 1, 3, 3, 3])\n",
            "torch.Size([1, 144, 192, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}